[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=22abab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=1e2fab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=1e94ab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=12d8ab0
[0] MPI startup(): Multi-threaded optimized library
[0] MPI startup(): shm data transfer mode
[1] MPI startup(): shm data transfer mode
[2] MPI startup(): shm data transfer mode
[3] MPI startup(): shm data transfer mode
[0] MPI startup(): Rank    Pid      Node name  Pin cpu
[0] MPI startup(): 0       25904    c7128      +1
[0] MPI startup(): 1       25905    c7128      +1
[0] MPI startup(): 2       25906    c7128      +1
[0] MPI startup(): 3       25907    c7128      +1
[0] MPI startup(): I_MPI_DEBUG=5
#------------------------------------------------------------
#    Intel (R) MPI Benchmarks 4.1 Update 1, MPI-1 part    
#------------------------------------------------------------
# Date                  : Mon Nov 14 11:23:44 2016
# Machine               : x86_64
# System                : Linux
# Release               : 2.6.32-573.12.1.el6.x86_64
# Version               : #1 SMP Mon Nov 23 12:55:32 EST 2015
# MPI Version           : 3.0
# MPI Thread Environment: 

# New default behavior from Version 3.2 on:

# the number of iterations per message size is cut down 
# dynamically when a certain run time (per message size sample) 
# is expected to be exceeded. Time limit is defined by variable 
# "SECS_PER_SAMPLE" (=> IMB_settings.h) 
# or through the flag => -time 
  


# Calling sequence was: 

# /opt/cesga/intel/impi/5.1.3.223/bin64/IMB-MPI1 alltoall

# Minimum message length in bytes:   0
# Maximum message length in bytes:   4194304
#
# MPI_Datatype                   :   MPI_BYTE 
# MPI_Datatype for reductions    :   MPI_FLOAT
# MPI_Op                         :   MPI_SUM  
#
#

# List of Benchmarks to run:

# Alltoall

#----------------------------------------------------------------
# Benchmarking Alltoall 
# #processes = 2 
# ( 2 additional processes waiting in MPI_Barrier)
#----------------------------------------------------------------
       #bytes #repetitions  t_min[usec]  t_max[usec]  t_avg[usec]
            0         1000         0.07         0.08         0.08
            1         1000         0.66         0.67         0.67
            2         1000         0.62         0.64         0.63
            4         1000         0.62         0.62         0.62
            8         1000         0.62         0.64         0.63
           16         1000         0.60         0.61         0.61
           32         1000         0.60         0.63         0.62
           64         1000         0.73         0.74         0.74
          128         1000         0.69         0.71         0.70
          256         1000         0.72         0.73         0.72
          512         1000         1.16         1.16         1.16
         1024         1000         1.29         1.32         1.30
         2048         1000         1.54         1.54         1.54
         4096         1000         2.15         2.16         2.15
         8192         1000         3.22         3.24         3.23
        16384         1000         5.17         5.19         5.18
        32768         1000         8.89         8.89         8.89
        65536          640        11.81        11.81        11.81
       131072          320        24.23        24.25        24.24
       262144          160        50.49        50.54        50.51
       524288           80        97.07        97.15        97.11
      1048576           40       183.35       183.37       183.36
      2097152           20       365.48       365.60       365.54
      4194304           10      1236.20      1236.20      1236.20

#----------------------------------------------------------------
# Benchmarking Alltoall 
# #processes = 4 
#----------------------------------------------------------------
       #bytes #repetitions  t_min[usec]  t_max[usec]  t_avg[usec]
            0         1000         0.07         0.08         0.07
            1         1000         1.28         1.29         1.28
            2         1000         1.26         1.28         1.27
            4         1000         1.24         1.26         1.25
            8         1000         1.27         1.28         1.28
           16         1000         1.24         1.24         1.24
           32         1000         1.30         1.31         1.30
           64         1000         1.36         1.37         1.36
          128         1000         1.47         1.49         1.48
          256         1000         1.49         1.51         1.50
          512         1000         2.04         2.05         2.05
         1024         1000         2.32         2.33         2.33
         2048         1000         2.84         2.86         2.85
         4096         1000         4.05         4.07         4.06
         8192         1000         6.01         6.02         6.02
        16384         1000        11.06        11.09        11.08
        32768         1000        22.93        22.94        22.94
        65536          640        30.47        30.51        30.50
       131072          320        55.76        55.80        55.77
       262144          160       106.56       106.61       106.58
       524288           80       211.00       211.34       211.14
      1048576           40       647.15       648.80       647.95
      2097152           20      1947.61      1970.88      1964.02
      4194304           10      3936.31      3959.70      3948.78


# All processes entering MPI_Finalize

