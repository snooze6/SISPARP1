[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=1fdeab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=1e7aab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=2208ab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=2038ab0
[0] MPI startup(): Multi-threaded optimized library
[0] MPI startup(): shm data transfer mode
[1] MPI startup(): shm data transfer mode
[2] MPI startup(): shm data transfer mode
[3] MPI startup(): shm data transfer mode
[0] MPI startup(): Rank    Pid      Node name  Pin cpu
[0] MPI startup(): 0       26121    c7128      +1
[0] MPI startup(): 1       26122    c7128      +1
[0] MPI startup(): 2       26123    c7128      +1
[0] MPI startup(): 3       26124    c7128      +1
[0] MPI startup(): I_MPI_DEBUG=5
#------------------------------------------------------------
#    Intel (R) MPI Benchmarks 4.1 Update 1, MPI-1 part    
#------------------------------------------------------------
# Date                  : Mon Nov 14 11:23:50 2016
# Machine               : x86_64
# System                : Linux
# Release               : 2.6.32-573.12.1.el6.x86_64
# Version               : #1 SMP Mon Nov 23 12:55:32 EST 2015
# MPI Version           : 3.0
# MPI Thread Environment: 

# New default behavior from Version 3.2 on:

# the number of iterations per message size is cut down 
# dynamically when a certain run time (per message size sample) 
# is expected to be exceeded. Time limit is defined by variable 
# "SECS_PER_SAMPLE" (=> IMB_settings.h) 
# or through the flag => -time 
  


# Calling sequence was: 

# /opt/cesga/intel/impi/5.1.3.223/bin64/IMB-MPI1 barrier

# Minimum message length in bytes:   0
# Maximum message length in bytes:   4194304
#
# MPI_Datatype                   :   MPI_BYTE 
# MPI_Datatype for reductions    :   MPI_FLOAT
# MPI_Op                         :   MPI_SUM  
#
#

# List of Benchmarks to run:

# Barrier

#---------------------------------------------------
# Benchmarking Barrier 
# #processes = 2 
# ( 2 additional processes waiting in MPI_Barrier)
#---------------------------------------------------
 #repetitions  t_min[usec]  t_max[usec]  t_avg[usec]
         1000         0.46         0.46         0.46

#---------------------------------------------------
# Benchmarking Barrier 
# #processes = 4 
#---------------------------------------------------
 #repetitions  t_min[usec]  t_max[usec]  t_avg[usec]
         1000         0.93         0.93         0.93


# All processes entering MPI_Finalize

