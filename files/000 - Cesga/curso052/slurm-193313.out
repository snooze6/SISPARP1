[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=210eab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=a92ab0
[0] MPI startup(): Multi-threaded optimized library
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=b33ab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=1a73ab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=f9fab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=a8cab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=1a5eab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=1526ab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=847ab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=115aab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=13dcab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=1c4cab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=193eab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=223bab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=da1ab0
[-1] MPI startup(): Imported environment partly inaccesible. Map=0 Info=67dab0
[13] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[7] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[13] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[13] MPI startup(): dapl data transfer mode
[2] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[6] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[10] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[7] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[7] MPI startup(): dapl data transfer mode
[2] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[2] MPI startup(): dapl data transfer mode
[6] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[6] MPI startup(): dapl data transfer mode
[10] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[0] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[10] MPI startup(): dapl data transfer mode
[4] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[14] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[0] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[0] MPI startup(): dapl data transfer mode
[4] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[4] MPI startup(): dapl data transfer mode
[14] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[14] MPI startup(): dapl data transfer mode
[12] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[5] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[9] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[8] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[1] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[12] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[12] MPI startup(): dapl data transfer mode
[15] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[11] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[5] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[9] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[9] MPI startup(): dapl data transfer mode
[5] MPI startup(): dapl data transfer mode
[3] DAPL startup(): trying to open DAPL provider from I_MPI_DAPL_PROVIDER: ofa-v2-mlx4_0-1u
[1] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[8] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[1] MPI startup(): dapl data transfer mode
[8] MPI startup(): dapl data transfer mode
[15] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[15] MPI startup(): dapl data transfer mode
[11] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[11] MPI startup(): dapl data transfer mode
[3] MPI startup(): DAPL provider ofa-v2-mlx4_0-1u
[3] MPI startup(): dapl data transfer mode
[4] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[4] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[6] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[6] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[7] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[7] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[8] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[8] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[11] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[11] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[1] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[1] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[9] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[9] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[12] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[12] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[5] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[5] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[10] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[10] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[13] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[13] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[2] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[2] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[14] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[14] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[3] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[3] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[0] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[0] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[15] MPID_nem_init_dapl_coll_fns(): User set DAPL collective mask = 0000
[15] MPID_nem_init_dapl_coll_fns(): Effective DAPL collective mask = 0000
[0] MPI startup(): Rank    Pid      Node name  Pin cpu
[0] MPI startup(): 0       398      c7001      +1
[0] MPI startup(): 1       18318    c7010      +1
[0] MPI startup(): 2       23836    c7011      +1
[0] MPI startup(): 3       28771    c7013      +1
[0] MPI startup(): 4       2913     c7014      +1
[0] MPI startup(): 5       2726     c7015      +1
[0] MPI startup(): 6       18641    c7016      +1
[0] MPI startup(): 7       24354    c7047      +1
[0] MPI startup(): 8       17668    c7108      +1
[0] MPI startup(): 9       2971     c7109      +1
Hello world from processor 5 out of 16 processors
Hello world from processor 9 out of 16 processors
Hello world from processor 11 out of 16 processors
Hello world from processor 1 out of 16 processors
Hello world from processor 13 out of 16 processors
Hello world from processor 12 out of 16 processors
Hello world from processor 6 out of 16 processors
Hello world from processor 8 out of 16 processors
Hello world from processor 4 out of 16 processors
Hello world from processor 2 out of 16 processors
Hello world from processor 3 out of 16 processors
Hello world from processor 10 out of 16 processors
Hello world from processor 14 out of 16 processors
[0] MPI startup(): 10      24274    c7112      +1
[0] MPI startup(): 11      26801    c7116      +1
[0] MPI startup(): 12      20551    c7249      +1
[0] MPI startup(): 13      13694    c7250      +1
[0] MPI startup(): 14      24897    c7251      +1
[0] MPI startup(): 15      513      c7252      +1
Hello world from processor 7 out of 16 processors
Hello world from processor 15 out of 16 processors
[0] MPI startup(): I_MPI_DEBUG=5
Hello world from processor 0 out of 16 processors
